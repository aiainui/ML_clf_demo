{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### origin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>题型ID</th>\n",
       "      <th>试题ID</th>\n",
       "      <th>材料</th>\n",
       "      <th>题干</th>\n",
       "      <th>选项</th>\n",
       "      <th>答案</th>\n",
       "      <th>解析</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127</td>\n",
       "      <td>562593</td>\n",
       "      <td>Where I'm from， we're pretty [u]　　1　　[/u](re...</td>\n",
       "      <td>[blank=4]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[|||]to be[|||]</td>\n",
       "      <td>句意：所以我要努力做到准时。make an effort  to do sth努力做某事，所...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127</td>\n",
       "      <td>562596</td>\n",
       "      <td>Where I'm from， we're pretty [u]　　1　　[/u](re...</td>\n",
       "      <td>[blank=4]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[|||]to meet[|||]</td>\n",
       "      <td>句意：如果有人邀请你在中午见他，你被期待中午到那里。invite sb to do sth邀...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127</td>\n",
       "      <td>562597</td>\n",
       "      <td>Where I'm from， we're pretty [u]　　1　　[/u](re...</td>\n",
       "      <td>[blank=4]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[|||]to be[|||]</td>\n",
       "      <td>句意：在瑞士，准时是重要的。此处填写动词不定式to be，在句中做真实主语。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127</td>\n",
       "      <td>562598</td>\n",
       "      <td>Where I'm from， we're pretty [u]　　1　　[/u](re...</td>\n",
       "      <td>[blank=4]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[|||]seeing[|||]</td>\n",
       "      <td>句意：我们经常围绕中心散步，尽可能多地看见我们的朋友。此处填写现在分词seeing，作伴随状语。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127</td>\n",
       "      <td>562599</td>\n",
       "      <td>Where I'm from， we're pretty [u]　　1　　[/u](re...</td>\n",
       "      <td>[blank=4]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[|||]to shake[|||]</td>\n",
       "      <td>句意：当我们彼此见面时，握手是有礼貌的。此处填写动词不定式to shake，在句中做真实主语。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   题型ID    试题ID                                                 材料         题干  \\\n",
       "0   127  562593  　　Where I'm from， we're pretty [u]　　1　　[/u](re...  [blank=4]   \n",
       "1   127  562596  　　Where I'm from， we're pretty [u]　　1　　[/u](re...  [blank=4]   \n",
       "2   127  562597  　　Where I'm from， we're pretty [u]　　1　　[/u](re...  [blank=4]   \n",
       "3   127  562598  　　Where I'm from， we're pretty [u]　　1　　[/u](re...  [blank=4]   \n",
       "4   127  562599  　　Where I'm from， we're pretty [u]　　1　　[/u](re...  [blank=4]   \n",
       "\n",
       "   选项                  答案                                                 解析  \n",
       "0 NaN     [|||]to be[|||]  句意：所以我要努力做到准时。make an effort  to do sth努力做某事，所...  \n",
       "1 NaN   [|||]to meet[|||]  句意：如果有人邀请你在中午见他，你被期待中午到那里。invite sb to do sth邀...  \n",
       "2 NaN     [|||]to be[|||]             句意：在瑞士，准时是重要的。此处填写动词不定式to be，在句中做真实主语。  \n",
       "3 NaN    [|||]seeing[|||]   句意：我们经常围绕中心散步，尽可能多地看见我们的朋友。此处填写现在分词seeing，作伴随状语。  \n",
       "4 NaN  [|||]to shake[|||]    句意：当我们彼此见面时，握手是有礼貌的。此处填写动词不定式to shake，在句中做真实主语。  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "题型ID\n",
       "38     1914\n",
       "39      856\n",
       "40     3723\n",
       "42     1078\n",
       "43      236\n",
       "44     1992\n",
       "45     2093\n",
       "46     2379\n",
       "47     5729\n",
       "48       60\n",
       "49     4449\n",
       "127    1604\n",
       "142     457\n",
       "146    1957\n",
       "148    1144\n",
       "264     570\n",
       "399     853\n",
       "400     154\n",
       "432     485\n",
       "433    2651\n",
       "434     141\n",
       "435    1463\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"题型ID\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get feature data and split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.utils.extmath import density\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fill_problem_feature2\",\"r\") as f:\n",
    "    features = f.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35986"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['127\\t562593\\t0 0 0 0 21 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 23 4 364 5 0 10 0 0 0 0 0 0 10 10 \\n',\n",
       " '127\\t562596\\t0 0 0 0 34 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 21 6 364 5 0 10 0 0 0 0 0 0 10 10 \\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'127\\t895697\\t0 0 0 0 32 17 0 0 0 7 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 47 4 456 5 0 13 0 0 1 0 0 0 14 14 \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(data_dir):\n",
    "    with open(data_dir,'r',encoding='utf-8') as f:\n",
    "        data_list = f.readlines()\n",
    "    X,Y,ID = [],[],[]\n",
    "    for line in data_list:\n",
    "        y = int(line.split('\\t')[0])\n",
    "        i = int(line.split('\\t')[1])\n",
    "        x = [float(n) for n in line.split('\\t')[2].split()]\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        ID.append(i)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    x_train,x_test,y_train,y_test,id_train,id_test = train_test_split(X,Y,ID,test_size=0.3,random_state=0)\n",
    "    return x_train,x_test,y_train,y_test,id_train,id_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test ,id_train,id_test =  get_data(\"fill_problem_feature2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data : 25190\n",
      "test_data : 10796\n"
     ]
    }
   ],
   "source": [
    "print(\"train data : {}\".format(len(x_train)))\n",
    "print(\"test_data : {}\".format(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experiment with models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(x_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(x_test)\n",
    "    pred_train = clf.predict(x_train)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_train,pred_train )\n",
    "    print(\"train accuracy:   %0.3f\" % score)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"test accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "\n",
    "    print(\"confusion matrix:\")\n",
    "    matrix = metrics.confusion_matrix(y_test, pred)\n",
    "    for line in matrix :\n",
    "        for n in line:\n",
    "            print(\"{:<8}\".format(n),end = '')\n",
    "        print() \n",
    "    print (\"test result\")\n",
    "    print(metrics.classification_report(y_test, pred,digits=4))\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    names = []\n",
    "    results = []\n",
    "    for clf, name in (\n",
    "            (LogisticRegression() , \"LR\"),\n",
    "            (Pipeline([('sc', StandardScaler()),('clf', LogisticRegression())]),\"LR with normalize\"),\n",
    "            (SGDClassifier(),\"SGD\"),\n",
    "            (Perceptron(), \"Perceptron\"),\n",
    "            (SVC(kernel='rbf'),\"SVM with rbf\"),\n",
    "            (LinearSVC(),\"LinearSVC\"),\n",
    "            (MultinomialNB(),\"MultinomialNB\"),\n",
    "            (BernoulliNB(),\"BernoulliNB\"),\n",
    "            (MLPClassifier((100,50)),\"Neural Network\"),\n",
    "            (GradientBoostingClassifier(),\"GBDT\"),\n",
    "            (RandomForestClassifier(), \"Random forest\"),\n",
    "            (xgb.XGBClassifier(),\"XGBoost\")):\n",
    "        print('=' * 80)\n",
    "        print(name)\n",
    "        result = benchmark(clf)\n",
    "        names.append(name)\n",
    "        results.append(result)\n",
    "    return names,results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LR\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 10.595s\n",
      "test time:  0.048s\n",
      "train accuracy:   0.795\n",
      "test accuracy:   0.787\n",
      "dimensionality: 44\n",
      "density: 0.863636\n",
      "confusion matrix:\n",
      "426     8       72      0       0       6       36      0       1       0       15      10      0       12      2       0       1       0       0       1       0       0       \n",
      "10      107     11      0       3       12      1       3       8       0       0       1       2       0       47      0       1       6       0       66      0       0       \n",
      "118     1       807     6       0       2       14      0       0       0       22      6       0       106     0       0       1       0       0       0       0       3       \n",
      "0       5       5       280     0       0       0       1       1       0       0       0       1       1       0       3       0       0       0       10      0       0       \n",
      "0       0       0       0       44      0       0       0       14      0       0       0       0       0       0       6       1       0       3       5       0       0       \n",
      "7       4       17      0       0       531     5       5       23      0       1       4       1       0       8       3       0       0       0       9       0       0       \n",
      "4       8       5       0       0       1       529     3       2       0       1       0       1       46      10      2       0       2       0       6       0       0       \n",
      "0       0       2       0       0       2       0       588     100     0       0       0       17      0       0       18      0       0       0       8       0       0       \n",
      "0       0       5       0       0       1       0       6       1631    0       2       53      2       10      0       0       0       0       4       11      0       0       \n",
      "0       0       0       0       0       0       0       0       4       12      0       0       0       0       0       1       0       0       0       0       0       0       \n",
      "0       0       24      0       0       4       0       0       0       0       1270    3       0       6       0       0       2       0       0       0       0       0       \n",
      "0       0       74      0       0       1       2       0       11      0       11      314     0       39      0       0       0       0       0       2       0       11      \n",
      "0       0       0       0       0       1       0       13      51      0       0       0       77      0       0       0       0       0       0       0       0       0       \n",
      "6       0       159     0       0       13      10      1       4       0       27      100     0       249     0       0       2       0       0       1       0       0       \n",
      "0       19      0       5       0       2       0       3       3       0       0       0       0       1       291     0       4       3       0       22      0       0       \n",
      "0       14      0       0       0       0       0       1       19      0       0       0       0       3       3       82      0       0       11      31      0       0       \n",
      "0       0       0       1       0       0       0       0       18      0       3       0       1       6       0       15      183     0       0       2       0       0       \n",
      "0       0       0       3       0       0       0       0       0       0       0       0       0       0       15      1       0       11      0       10      0       0       \n",
      "0       0       0       0       0       0       0       0       6       0       0       0       0       0       0       0       0       0       124     14      0       0       \n",
      "0       3       5       1       0       8       0       3       28      0       0       0       1       1       0       7       1       2       2       725     0       37      \n",
      "0       0       0       0       0       1       0       0       0       1       0       0       0       0       0       1       0       0       0       45      0       0       \n",
      "0       0       8       1       0       3       0       0       15      0       0       2       1       7       0       5       0       0       2       196     0       217     \n",
      "test result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          38     0.7461    0.7220    0.7339       590\n",
      "          39     0.6331    0.3849    0.4787       278\n",
      "          40     0.6759    0.7431    0.7079      1086\n",
      "          42     0.9428    0.9121    0.9272       307\n",
      "          43     0.9362    0.6027    0.7333        73\n",
      "          44     0.9031    0.8592    0.8806       618\n",
      "          45     0.8861    0.8532    0.8694       620\n",
      "          46     0.9378    0.8000    0.8634       735\n",
      "          47     0.8412    0.9455    0.8903      1725\n",
      "          48     0.9231    0.7059    0.8000        17\n",
      "          49     0.9393    0.9702    0.9545      1309\n",
      "         127     0.6369    0.6753    0.6555       465\n",
      "         142     0.7404    0.5423    0.6260       142\n",
      "         146     0.5113    0.4353    0.4703       572\n",
      "         148     0.7739    0.8244    0.7984       353\n",
      "         264     0.5694    0.5000    0.5325       164\n",
      "         399     0.9337    0.7991    0.8612       229\n",
      "         400     0.4583    0.2750    0.3437        40\n",
      "         432     0.8493    0.8611    0.8552       144\n",
      "         433     0.6229    0.8799    0.7294       824\n",
      "         434     0.0000    0.0000    0.0000        48\n",
      "         435     0.8097    0.4748    0.5986       457\n",
      "\n",
      "   micro avg     0.7871    0.7871    0.7871     10796\n",
      "   macro avg     0.7396    0.6712    0.6959     10796\n",
      "weighted avg     0.7872    0.7871    0.7809     10796\n",
      "\n",
      "================================================================================\n",
      "LR with normalize\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(memory=None,\n",
      "     steps=[('sc', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 15.287s\n",
      "test time:  0.019s\n",
      "train accuracy:   0.796\n",
      "test accuracy:   0.790\n",
      "confusion matrix:\n",
      "426     8       72      0       0       5       36      0       1       0       15      9       0       14      2       0       1       0       0       1       0       0       \n",
      "6       112     9       0       3       17      1       3       3       0       0       0       1       0       47      0       1       4       0       71      0       0       \n",
      "120     1       806     3       0       2       12      0       0       0       21      7       0       111     0       0       1       0       0       0       0       2       \n",
      "0       5       5       280     0       0       0       1       1       0       0       0       1       1       0       3       0       0       0       10      0       0       \n",
      "0       0       0       0       44      0       0       0       14      0       0       0       0       0       0       5       1       0       4       5       0       0       \n",
      "7       4       15      0       0       537     1       2       25      0       1       4       2       1       7       2       0       0       0       9       0       1       \n",
      "3       7       6       0       0       2       529     4       1       0       1       0       1       45      12      2       0       0       0       7       0       0       \n",
      "0       0       2       0       0       2       0       586     99      0       0       0       16      0       0       21      0       0       0       9       0       0       \n",
      "0       1       6       0       0       1       0       5       1632    0       2       51      2       9       0       0       0       0       4       12      0       0       \n",
      "0       0       0       0       0       0       2       0       2       8       0       0       0       0       0       5       0       0       0       0       0       0       \n",
      "0       0       25      0       0       4       0       0       0       0       1270    3       0       5       0       0       2       0       0       0       0       0       \n",
      "0       0       74      0       0       0       1       0       10      0       11      318     0       39      0       0       0       0       0       1       0       11      \n",
      "0       0       0       0       0       3       0       13      43      0       0       0       83      0       0       0       0       0       0       0       0       0       \n",
      "6       0       159     0       0       13      6       1       4       0       24      98      0       257     0       0       2       1       0       1       0       0       \n",
      "2       15      0       5       0       3       0       1       1       0       0       0       0       1       295     0       4       0       0       25      1       0       \n",
      "0       14      0       0       0       1       0       1       16      0       0       0       0       3       3       84      0       0       11      31      0       0       \n",
      "0       0       0       1       1       0       0       0       16      0       3       0       1       6       0       15      184     0       0       2       0       0       \n",
      "0       0       0       3       0       0       0       0       0       0       0       0       0       0       21      1       0       4       0       11      0       0       \n",
      "0       0       0       0       0       0       0       0       5       0       0       0       0       0       0       0       0       0       126     13      0       0       \n",
      "0       3       5       1       0       7       0       4       25      0       0       0       2       1       0       7       0       2       5       731     0       31      \n",
      "0       0       0       0       0       0       0       0       0       0       0       0       1       0       0       2       0       0       0       45      0       0       \n",
      "0       0       8       1       0       2       0       0       13      0       0       2       1       7       0       6       0       0       2       199     0       216     \n",
      "test result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          38     0.7474    0.7220    0.7345       590\n",
      "          39     0.6588    0.4029    0.5000       278\n",
      "          40     0.6762    0.7422    0.7076      1086\n",
      "          42     0.9524    0.9121    0.9318       307\n",
      "          43     0.9167    0.6027    0.7273        73\n",
      "          44     0.8965    0.8689    0.8825       618\n",
      "          45     0.8997    0.8532    0.8758       620\n",
      "          46     0.9436    0.7973    0.8643       735\n",
      "          47     0.8540    0.9461    0.8977      1725\n",
      "          48     1.0000    0.4706    0.6400        17\n",
      "          49     0.9421    0.9702    0.9560      1309\n",
      "         127     0.6463    0.6839    0.6646       465\n",
      "         142     0.7477    0.5845    0.6561       142\n",
      "         146     0.5140    0.4493    0.4795       572\n",
      "         148     0.7623    0.8357    0.7973       353\n",
      "         264     0.5490    0.5122    0.5300       164\n",
      "         399     0.9388    0.8035    0.8659       229\n",
      "         400     0.3636    0.1000    0.1569        40\n",
      "         432     0.8289    0.8750    0.8514       144\n",
      "         433     0.6179    0.8871    0.7285       824\n",
      "         434     0.0000    0.0000    0.0000        48\n",
      "         435     0.8276    0.4726    0.6017       457\n",
      "\n",
      "   micro avg     0.7899    0.7899    0.7899     10796\n",
      "   macro avg     0.7402    0.6587    0.6841     10796\n",
      "weighted avg     0.7913    0.7899    0.7838     10796\n",
      "\n",
      "================================================================================\n",
      "SGD\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.368s\n",
      "test time:  0.006s\n",
      "train accuracy:   0.342\n",
      "test accuracy:   0.341\n",
      "dimensionality: 44\n",
      "density: 0.813017\n",
      "confusion matrix:\n",
      "0       0       590     0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       \n",
      "13      17      139     4       14      0       43      3       7       0       6       0       1       2       2       0       3       0       0       14      0       10      \n",
      "0       0       1077    6       0       0       0       0       0       0       3       0       0       0       0       0       0       0       0       0       0       0       \n",
      "0       0       24      266     2       0       0       2       0       0       0       0       1       1       0       0       0       0       0       5       0       6       \n",
      "0       0       1       4       4       0       2       4       11      0       0       0       0       0       0       0       2       0       0       2       0       43      \n",
      "1       0       562     0       27      0       21      2       0       0       0       0       0       0       1       0       0       0       0       0       0       4       \n",
      "3       0       595     0       7       0       2       3       0       0       0       0       2       1       0       0       0       0       0       4       0       3       \n",
      "0       0       3       2       22      5       6       486     36      0       0       0       113     0       0       0       0       0       0       3       0       59      \n",
      "0       3       144     1       2       41      19      94      968     0       0       1       130     6       0       0       25      0       0       36      0       255     \n",
      "0       0       4       0       0       0       1       0       3       0       0       0       0       0       0       0       3       0       0       2       0       4       \n",
      "1       0       1197    0       0       0       0       0       0       0       111     0       0       0       0       0       0       0       0       0       0       0       \n",
      "1       0       446     0       3       0       0       0       0       0       0       0       0       0       0       0       0       0       0       6       0       9       \n",
      "0       0       0       1       0       5       0       5       15      0       0       0       88      0       0       0       0       0       0       0       0       28      \n",
      "0       0       560     0       1       0       0       0       0       0       6       0       0       4       0       0       0       0       0       1       0       0       \n",
      "0       4       248     7       30      0       29      2       0       0       0       0       0       0       3       0       1       0       0       18      0       11      \n",
      "0       0       30      0       4       2       6       5       3       0       0       0       0       0       0       0       7       0       0       8       0       99      \n",
      "0       2       12      0       0       0       0       1       14      0       0       0       1       0       0       0       92      0       0       3       0       104     \n",
      "0       0       0       4       0       0       4       3       0       0       0       0       0       0       0       0       0       0       0       21      0       8       \n",
      "0       0       2       0       1       0       1       2       3       0       0       0       0       0       0       0       0       0       0       1       0       134     \n",
      "0       17      12      2       50      0       40      58      3       0       0       0       3       1       0       0       1       0       0       303     0       334     \n",
      "0       0       0       0       0       0       2       0       0       0       0       0       0       0       0       0       0       0       0       2       0       44      \n",
      "0       4       39      2       65      0       7       1       0       0       0       0       0       0       0       0       0       0       0       75      0       264     \n",
      "test result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          38     0.0000    0.0000    0.0000       590\n",
      "          39     0.3617    0.0612    0.1046       278\n",
      "          40     0.1894    0.9917    0.3181      1086\n",
      "          42     0.8896    0.8664    0.8779       307\n",
      "          43     0.0172    0.0548    0.0262        73\n",
      "          44     0.0000    0.0000    0.0000       618\n",
      "          45     0.0109    0.0032    0.0050       620\n",
      "          46     0.7243    0.6612    0.6913       735\n",
      "          47     0.9106    0.5612    0.6944      1725\n",
      "          48     0.0000    0.0000    0.0000        17\n",
      "          49     0.8810    0.0848    0.1547      1309\n",
      "         127     0.0000    0.0000    0.0000       465\n",
      "         142     0.2596    0.6197    0.3659       142\n",
      "         146     0.2667    0.0070    0.0136       572\n",
      "         148     0.5000    0.0085    0.0167       353\n",
      "         264     0.0000    0.0000    0.0000       164\n",
      "         399     0.6866    0.4017    0.5069       229\n",
      "         400     0.0000    0.0000    0.0000        40\n",
      "         432     0.0000    0.0000    0.0000       144\n",
      "         433     0.6012    0.3677    0.4563       824\n",
      "         434     0.0000    0.0000    0.0000        48\n",
      "         435     0.1860    0.5777    0.2814       457\n",
      "\n",
      "   micro avg     0.3413    0.3413    0.3413     10796\n",
      "   macro avg     0.2948    0.2394    0.2051     10796\n",
      "weighted avg     0.4583    0.3413    0.3005     10796\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=None, penalty=None, random_state=0, shuffle=True, tol=None,\n",
      "      validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.348s\n",
      "test time:  0.005s\n",
      "train accuracy:   0.301\n",
      "test accuracy:   0.301\n",
      "dimensionality: 44\n",
      "density: 0.809917\n",
      "confusion matrix:\n",
      "0       0       0       0       0       0       589     0       0       0       0       1       0       0       0       0       0       0       0       0       0       0       \n",
      "0       15      1       3       0       0       212     1       13      2       2       0       0       2       12      0       3       0       0       10      0       2       \n",
      "0       0       0       6       0       0       1080    0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       \n",
      "0       0       0       257     0       0       31      0       0       0       0       0       1       1       8       0       6       0       0       3       0       0       \n",
      "0       0       0       1       0       0       6       0       17      0       0       0       0       0       3       0       36      0       0       9       0       1       \n",
      "0       0       0       0       0       0       606     0       2       4       0       0       0       0       3       0       1       0       0       1       0       1       \n",
      "0       0       0       0       0       1       606     5       0       0       0       0       1       3       0       0       0       0       0       4       0       0       \n",
      "0       0       0       0       2       5       9       538     102     13      0       0       0       0       6       0       4       0       0       45      0       11      \n",
      "0       0       0       0       16      26      155     114     1215    0       0       4       9       19      0       0       0       0       0       167     0       0       \n",
      "0       0       0       0       0       0       6       0       3       0       0       0       0       0       5       0       0       0       0       3       0       0       \n",
      "0       0       0       0       0       0       1299    0       0       0       10      0       0       0       0       0       0       0       0       0       0       0       \n",
      "0       0       0       0       0       0       441     0       3       6       0       11      0       0       0       0       0       0       0       4       0       0       \n",
      "0       0       0       0       0       0       0       23      70      0       0       0       26      1       0       0       1       0       1       0       0       20      \n",
      "0       0       0       0       0       1       551     0       0       2       6       0       0       12      0       0       0       0       0       0       0       0       \n",
      "0       3       0       6       0       0       314     1       1       0       0       0       0       0       16      0       1       0       0       11      0       0       \n",
      "0       0       0       0       0       0       40      4       5       1       0       0       7       1       7       0       2       0       0       88      0       9       \n",
      "0       0       0       0       0       1       12      2       20      0       0       0       9       0       0       0       104     0       0       74      0       7       \n",
      "0       0       0       4       0       0       10      0       1       1       0       0       0       0       11      0       0       0       0       13      0       0       \n",
      "0       0       0       0       0       0       3       1       9       0       0       0       0       0       0       0       1       0       1       122     0       7       \n",
      "0       4       0       0       1       0       149     16      18      55      0       0       0       1       143     0       13      0       0       388     0       36      \n",
      "0       0       0       0       0       0       2       1       0       0       0       0       0       0       2       0       1       0       0       39      0       3       \n",
      "0       0       0       2       0       0       91      0       3       88      0       0       0       0       8       0       6       0       0       209     0       50      \n",
      "test result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          38     0.0000    0.0000    0.0000       590\n",
      "          39     0.6818    0.0540    0.1000       278\n",
      "          40     0.0000    0.0000    0.0000      1086\n",
      "          42     0.9211    0.8371    0.8771       307\n",
      "          43     0.0000    0.0000    0.0000        73\n",
      "          44     0.0000    0.0000    0.0000       618\n",
      "          45     0.0976    0.9774    0.1774       620\n",
      "          46     0.7620    0.7320    0.7467       735\n",
      "          47     0.8198    0.7043    0.7577      1725\n",
      "          48     0.0000    0.0000    0.0000        17\n",
      "          49     0.5556    0.0076    0.0151      1309\n",
      "         127     0.6875    0.0237    0.0457       465\n",
      "         142     0.4906    0.1831    0.2667       142\n",
      "         146     0.3000    0.0210    0.0392       572\n",
      "         148     0.0714    0.0453    0.0555       353\n",
      "         264     0.0000    0.0000    0.0000       164\n",
      "         399     0.5810    0.4541    0.5098       229\n",
      "         400     0.0000    0.0000    0.0000        40\n",
      "         432     0.5000    0.0069    0.0137       144\n",
      "         433     0.3261    0.4709    0.3853       824\n",
      "         434     0.0000    0.0000    0.0000        48\n",
      "         435     0.3401    0.1094    0.1656       457\n",
      "\n",
      "   micro avg     0.3009    0.3009    0.3009     10796\n",
      "   macro avg     0.3243    0.2103    0.1889     10796\n",
      "weighted avg     0.4122    0.3009    0.2682     10796\n",
      "\n",
      "================================================================================\n",
      "SVM with rbf\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 125.938s\n",
      "test time:  65.078s\n",
      "train accuracy:   0.954\n",
      "test accuracy:   0.597\n",
      "confusion matrix:\n",
      "171     0       61      0       0       0       18      0       1       0       331     2       0       6       0       0       0       0       0       0       0       0       \n",
      "1       143     3       0       1       2       0       0       5       0       107     0       0       0       0       4       0       0       0       12      0       0       \n",
      "20      1       827     0       0       0       24      0       1       0       194     7       0       12      0       0       0       0       0       0       0       0       \n",
      "0       0       0       188     0       0       0       0       4       0       110     0       0       0       0       0       0       0       0       5       0       0       \n",
      "0       0       0       0       50      0       0       0       7       0       7       0       0       0       0       1       3       0       0       5       0       0       \n",
      "0       0       12      0       0       180     0       1       0       0       424     0       0       0       0       0       0       0       0       1       0       0       \n",
      "8       0       103     0       0       1       297     1       3       0       199     0       0       4       0       0       0       0       1       3       0       0       \n",
      "0       0       0       0       0       0       0       480     105     0       134     0       1       0       0       0       0       0       1       11      0       3       \n",
      "0       0       3       0       1       0       0       41      1431    0       238     2       0       1       0       5       0       0       0       3       0       0       \n",
      "0       1       0       0       1       0       0       0       1       9       4       0       0       0       0       0       0       0       0       1       0       0       \n",
      "1       0       30      0       0       0       2       0       5       0       1267    2       0       2       0       0       0       0       0       0       0       0       \n",
      "5       0       75      0       0       0       1       0       4       0       159     172     0       41      0       0       0       0       0       5       0       3       \n",
      "0       0       0       0       0       0       0       7       13      0       69      0       53      0       0       0       0       0       0       0       0       0       \n",
      "4       0       75      0       0       0       9       0       2       0       199     34      0       246     0       0       0       0       0       1       0       2       \n",
      "0       0       0       0       1       0       0       0       4       0       317     0       0       1       23      0       0       0       0       7       0       0       \n",
      "0       2       1       0       0       0       0       1       29      0       14      0       0       0       0       65      18      0       14      14      0       6       \n",
      "0       0       0       0       0       0       0       1       35      0       8       2       0       6       0       9       157     0       5       4       0       2       \n",
      "0       0       0       1       0       0       0       0       4       0       13      0       0       0       1       0       0       2       0       19      0       0       \n",
      "0       0       0       0       1       0       0       0       48      0       12      0       0       0       0       11      14      0       45      10      0       3       \n",
      "0       1       1       1       0       0       2       12      53      0       168     1       0       0       1       17      7       1       10      478     1       70      \n",
      "0       0       0       0       1       0       0       4       13      0       6       0       0       0       0       2       5       0       9       8       0       0       \n",
      "0       0       4       0       0       0       0       2       31      0       145     2       0       0       0       1       4       0       6       96      0       166     \n",
      "test result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          38     0.8143    0.2898    0.4275       590\n",
      "          39     0.9662    0.5144    0.6714       278\n",
      "          40     0.6921    0.7615    0.7251      1086\n",
      "          42     0.9895    0.6124    0.7565       307\n",
      "          43     0.8929    0.6849    0.7752        73\n",
      "          44     0.9836    0.2913    0.4494       618\n",
      "          45     0.8414    0.4790    0.6105       620\n",
      "          46     0.8727    0.6531    0.7471       735\n",
      "          47     0.7954    0.8296    0.8121      1725\n",
      "          48     1.0000    0.5294    0.6923        17\n",
      "          49     0.3072    0.9679    0.4663      1309\n",
      "         127     0.7679    0.3699    0.4993       465\n",
      "         142     0.9815    0.3732    0.5408       142\n",
      "         146     0.7712    0.4301    0.5522       572\n",
      "         148     0.9200    0.0652    0.1217       353\n",
      "         264     0.5652    0.3963    0.4659       164\n",
      "         399     0.7548    0.6856    0.7185       229\n",
      "         400     0.6667    0.0500    0.0930        40\n",
      "         432     0.4945    0.3125    0.3830       144\n",
      "         433     0.6999    0.5801    0.6344       824\n",
      "         434     0.0000    0.0000    0.0000        48\n",
      "         435     0.6510    0.3632    0.4663       457\n",
      "\n",
      "   micro avg     0.5974    0.5974    0.5974     10796\n",
      "   macro avg     0.7467    0.4654    0.5277     10796\n",
      "weighted avg     0.7347    0.5974    0.5972     10796\n",
      "\n",
      "================================================================================\n",
      "LinearSVC\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 35.420s\n",
      "test time:  0.012s\n",
      "train accuracy:   0.516\n",
      "test accuracy:   0.515\n",
      "dimensionality: 44\n",
      "density: 0.839876\n",
      "confusion matrix:\n",
      "0       0       14      0       0       0       16      0       0       0       14      0       0       0       0       0       14      0       0       532     0       0       \n",
      "0       99      0       1       3       1       0       5       3       0       0       0       3       2       0       0       1       5       0       155     0       0       \n",
      "0       0       337     3       0       2       27      0       0       0       18      1       0       6       0       2       7       3       0       671     0       9       \n",
      "0       0       0       238     0       3       0       2       6       0       0       0       1       0       0       0       0       49      0       8       0       0       \n",
      "0       0       0       0       43      1       0       0       16      0       0       0       0       0       0       3       1       0       3       6       0       0       \n",
      "0       8       5       0       0       15      1       3       7       0       0       0       1       0       0       0       7       1       0       570     0       0       \n",
      "0       0       0       0       0       1       226     3       1       0       1       0       3       12      0       0       0       2       0       371     0       0       \n",
      "0       0       2       0       0       0       0       566     110     0       0       0       31      0       0       0       0       0       0       26      0       0       \n",
      "0       8       1       0       0       1       1       2       1551    0       2       1       3       1       0       0       91      0       4       58      0       1       \n",
      "0       0       0       0       0       0       0       0       3       11      0       0       0       0       0       0       0       2       0       1       0       0       \n",
      "0       0       3       0       0       0       1       0       0       0       954     0       0       0       0       0       13      0       0       338     0       0       \n",
      "0       0       48      0       0       6       7       0       3       0       19      70      0       0       0       0       107     0       0       191     0       14      \n",
      "0       0       0       0       0       0       0       11      44      0       0       0       87      0       0       0       0       0       0       0       0       0       \n",
      "0       0       85      0       0       11      78      1       0       0       21      14      5       71      0       4       45      0       0       236     0       1       \n",
      "0       3       0       4       0       1       2       6       2       0       0       0       0       0       0       0       1       9       0       325     0       0       \n",
      "0       3       0       0       0       0       0       5       57      0       0       0       0       0       0       15      2       0       10      72      0       0       \n",
      "0       0       0       0       1       0       0       1       28      0       0       0       1       0       0       1       193     0       0       4       0       0       \n",
      "0       0       0       3       0       0       0       2       0       0       0       0       0       0       0       0       0       20      0       15      0       0       \n",
      "0       0       0       0       0       0       0       0       5       0       0       0       0       0       0       0       0       0       123     16      0       0       \n",
      "0       1       1       1       0       0       0       26      30      1       0       0       2       3       0       0       0       2       2       725     0       30      \n",
      "0       0       0       0       0       0       0       0       0       1       0       0       1       0       0       0       0       0       0       46      0       0       \n",
      "0       0       2       0       0       0       0       2       17      0       0       1       6       1       0       0       2       2       2       205     0       217     \n",
      "test result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          38     0.0000    0.0000    0.0000       590\n",
      "          39     0.8115    0.3561    0.4950       278\n",
      "          40     0.6767    0.3103    0.4255      1086\n",
      "          42     0.9520    0.7752    0.8546       307\n",
      "          43     0.9149    0.5890    0.7167        73\n",
      "          44     0.3571    0.0243    0.0455       618\n",
      "          45     0.6295    0.3645    0.4617       620\n",
      "          46     0.8913    0.7701    0.8263       735\n",
      "          47     0.8237    0.8991    0.8598      1725\n",
      "          48     0.8462    0.6471    0.7333        17\n",
      "          49     0.9271    0.7288    0.8161      1309\n",
      "         127     0.8046    0.1505    0.2536       465\n",
      "         142     0.6042    0.6127    0.6084       142\n",
      "         146     0.7396    0.1241    0.2126       572\n",
      "         148     0.0000    0.0000    0.0000       353\n",
      "         264     0.6000    0.0915    0.1587       164\n",
      "         399     0.3988    0.8428    0.5414       229\n",
      "         400     0.2105    0.5000    0.2963        40\n",
      "         432     0.8542    0.8542    0.8542       144\n",
      "         433     0.1586    0.8799    0.2688       824\n",
      "         434     0.0000    0.0000    0.0000        48\n",
      "         435     0.7978    0.4748    0.5953       457\n",
      "\n",
      "   micro avg     0.5151    0.5151    0.5151     10796\n",
      "   macro avg     0.5908    0.4543    0.4556     10796\n",
      "weighted avg     0.6423    0.5151    0.5098     10796\n",
      "\n",
      "================================================================================\n",
      "MultinomialNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.012s\n",
      "test time:  0.008s\n",
      "train accuracy:   0.453\n",
      "test accuracy:   0.451\n",
      "dimensionality: 44\n",
      "density: 1.000000\n",
      "confusion matrix:\n",
      "369     6       41      0       0       18      72      0       0       0       46      17      0       19      2       0       0       0       0       0       0       0       \n",
      "40      55      1       3       11      23      13      6       2       3       6       2       3       1       17      10      2       7       7       13      8       45      \n",
      "221     9       271     6       0       5       131     0       0       0       210     143     0       84      0       0       0       0       0       0       0       6       \n",
      "3       2       0       241     6       0       1       3       0       0       0       0       3       0       5       1       0       37      0       1       3       1       \n",
      "0       3       0       0       37      0       0       8       1       1       0       0       7       0       0       0       0       1       12      1       2       0       \n",
      "48      29      7       1       4       399     5       2       1       4       39      12      0       5       32      5       1       12      0       0       1       11      \n",
      "109     12      34      0       0       0       393     4       0       3       18      10      1       20      9       0       0       0       5       1       0       1       \n",
      "0       6       0       0       0       0       2       619     0       2       0       0       38      2       0       11      0       3       48      0       1       3       \n",
      "2       8       0       0       12      1       0       1050    43      0       3       117     314     13      0       0       0       16      133     0       9       4       \n",
      "0       4       0       0       1       0       0       3       1       0       0       0       0       0       0       0       0       1       3       3       1       0       \n",
      "24      2       51      0       0       0       12      0       0       0       1134    41      0       45      0       0       0       0       0       0       0       0       \n",
      "9       1       31      0       0       0       13      0       2       0       26      308     0       60      0       0       0       0       0       2       3       10      \n",
      "0       0       0       0       0       0       0       13      0       0       0       0       111     0       0       0       0       0       16      0       2       0       \n",
      "17      14      52      0       0       7       41      0       5       0       136     147     0       151     0       1       0       0       0       1       0       0       \n",
      "6       68      0       6       6       36      0       1       0       1       0       0       0       1       192     1       0       3       4       12      11      5       \n",
      "11      8       0       0       0       3       5       57      0       3       1       2       8       1       1       7       0       2       44      4       4       3       \n",
      "0       0       0       0       6       0       0       58      0       0       1       11      23      0       0       0       45      1       64      0       19      1       \n",
      "0       0       0       3       1       0       0       4       0       1       0       0       0       0       0       3       0       5       5       6       11      1       \n",
      "0       2       0       0       0       0       0       10      0       0       0       0       0       0       0       0       0       1       129     1       1       0       \n",
      "2       15      0       0       11      0       7       106     3       39      0       0       1       0       0       119     11      5       95      220     86      104     \n",
      "0       0       0       0       0       0       0       6       0       0       0       0       1       0       0       0       1       1       31      0       8       0       \n",
      "0       8       13      2       0       0       21      16      3       11      0       3       1       0       0       63      10      1       63      91      14      137     \n",
      "test result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          38     0.4286    0.6254    0.5086       590\n",
      "          39     0.2183    0.1978    0.2075       278\n",
      "          40     0.5409    0.2495    0.3415      1086\n",
      "          42     0.9198    0.7850    0.8471       307\n",
      "          43     0.3895    0.5068    0.4405        73\n",
      "          44     0.8110    0.6456    0.7189       618\n",
      "          45     0.5489    0.6339    0.5883       620\n",
      "          46     0.3149    0.8422    0.4583       735\n",
      "          47     0.7049    0.0249    0.0482      1725\n",
      "          48     0.0000    0.0000    0.0000        17\n",
      "          49     0.7000    0.8663    0.7743      1309\n",
      "         127     0.3788    0.6624    0.4820       465\n",
      "         142     0.2172    0.7817    0.3400       142\n",
      "         146     0.3756    0.2640    0.3101       572\n",
      "         148     0.7442    0.5439    0.6285       353\n",
      "         264     0.0317    0.0427    0.0364       164\n",
      "         399     0.6429    0.1965    0.3010       229\n",
      "         400     0.0521    0.1250    0.0735        40\n",
      "         432     0.1958    0.8958    0.3213       144\n",
      "         433     0.6180    0.2670    0.3729       824\n",
      "         434     0.0435    0.1667    0.0690        48\n",
      "         435     0.4127    0.2998    0.3473       457\n",
      "\n",
      "   micro avg     0.4515    0.4515    0.4515     10796\n",
      "   macro avg     0.4222    0.4374    0.3734     10796\n",
      "weighted avg     0.5543    0.4515    0.4195     10796\n",
      "\n",
      "================================================================================\n",
      "BernoulliNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.017s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  0.016s\n",
      "train accuracy:   0.711\n",
      "test accuracy:   0.700\n",
      "dimensionality: 44\n",
      "density: 1.000000\n",
      "confusion matrix:\n",
      "384     10      42      0       0       0       98      0       0       0       29      19      0       4       1       0       0       0       0       3       0       0       \n",
      "23      81      8       0       10      12      0       0       0       0       2       2       1       0       49      10      1       1       0       75      0       3       \n",
      "226     2       555     3       0       0       29      0       0       0       196     8       0       67      0       0       0       0       0       0       0       0       \n",
      "0       5       5       250     5       0       7       0       1       0       0       0       1       6       0       11      0       0       0       9       7       0       \n",
      "0       0       0       0       45      1       0       0       14      0       0       0       0       0       1       1       3       0       3       5       0       0       \n",
      "10      2       21      9       0       396     2       0       7       1       6       7       0       12      9       3       0       0       0       88      1       44      \n",
      "9       6       7       2       0       2       523     1       3       0       6       0       2       33      19      0       0       0       0       7       0       0       \n",
      "0       7       2       4       0       2       0       531     134     0       0       0       9       10      0       0       4       0       0       32      0       0       \n",
      "0       1       7       0       1       9       0       13      1561    0       4       109     0       14      0       0       0       0       5       1       0       0       \n",
      "0       2       0       0       0       2       0       1       1       7       0       0       0       0       0       4       0       0       0       0       0       0       \n",
      "0       0       35      0       0       0       0       0       0       0       1237    28      0       5       0       0       0       0       0       4       0       0       \n",
      "0       0       66      0       0       5       0       0       4       0       28      302     0       46      0       0       0       0       0       9       0       5       \n",
      "0       0       0       3       0       5       0       9       52      0       0       0       41      0       0       9       0       0       0       23      0       0       \n",
      "5       8       148     0       0       11      6       0       0       0       116     109     0       168     0       0       0       0       0       1       0       0       \n",
      "6       11      0       3       0       2       0       0       2       0       0       0       1       1       297     0       4       1       0       25      0       0       \n",
      "0       2       0       0       1       0       0       0       12      0       0       3       0       2       3       32      0       0       10      99      0       0       \n",
      "0       0       0       2       1       0       0       0       6       0       0       8       1       4       0       15      178     0       0       14      0       0       \n",
      "0       2       0       2       0       0       0       0       0       1       0       0       0       0       22      0       0       4       0       6       0       3       \n",
      "0       0       0       0       0       2       0       0       3       0       0       0       0       0       0       0       0       0       126     13      0       0       \n",
      "0       5       5       1       0       17      0       2       27      1       1       0       1       1       3       6       0       2       3       649     2       98      \n",
      "0       0       0       0       0       0       0       0       0       1       0       0       0       0       0       0       0       0       0       45      2       0       \n",
      "0       0       36      1       0       1       0       0       19      0       0       2       0       0       0       2       0       0       1       207     2       186     \n",
      "test result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          38     0.5792    0.6508    0.6129       590\n",
      "          39     0.5625    0.2914    0.3839       278\n",
      "          40     0.5923    0.5110    0.5487      1086\n",
      "          42     0.8929    0.8143    0.8518       307\n",
      "          43     0.7143    0.6164    0.6618        73\n",
      "          44     0.8480    0.6408    0.7300       618\n",
      "          45     0.7865    0.8435    0.8140       620\n",
      "          46     0.9533    0.7224    0.8220       735\n",
      "          47     0.8456    0.9049    0.8743      1725\n",
      "          48     0.6364    0.4118    0.5000        17\n",
      "          49     0.7612    0.9450    0.8432      1309\n",
      "         127     0.5059    0.6495    0.5687       465\n",
      "         142     0.7193    0.2887    0.4121       142\n",
      "         146     0.4504    0.2937    0.3556       572\n",
      "         148     0.7351    0.8414    0.7847       353\n",
      "         264     0.3441    0.1951    0.2490       164\n",
      "         399     0.9368    0.7773    0.8496       229\n",
      "         400     0.5000    0.1000    0.1667        40\n",
      "         432     0.8514    0.8750    0.8630       144\n",
      "         433     0.4935    0.7876    0.6068       824\n",
      "         434     0.1429    0.0417    0.0645        48\n",
      "         435     0.5487    0.4070    0.4673       457\n",
      "\n",
      "   micro avg     0.6998    0.6998    0.6998     10796\n",
      "   macro avg     0.6546    0.5732    0.5923     10796\n",
      "weighted avg     0.7019    0.6998    0.6892     10796\n",
      "\n",
      "================================================================================\n",
      "Neural Network\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100, 50), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 30.959s\n",
      "test time:  0.081s\n",
      "train accuracy:   0.888\n",
      "test accuracy:   0.852\n",
      "confusion matrix:\n",
      "441     6       63      0       0       5       19      0       2       0       12      11      0       27      4       0       0       0       0       0       0       0       \n",
      "8       195     3       1       1       18      0       1       3       0       0       0       0       0       16      5       0       1       0       22      1       3       \n",
      "56      0       844     0       0       4       7       0       0       0       16      9       0       147     0       0       0       0       0       0       0       3       \n",
      "0       6       0       296     0       1       0       0       0       0       0       0       1       0       0       0       0       1       0       2       0       0       \n",
      "0       0       0       0       59      0       0       1       4       0       0       0       0       0       0       2       2       0       2       3       0       0       \n",
      "3       8       5       0       0       578     0       2       1       0       0       6       0       3       5       0       0       0       1       2       0       4       \n",
      "5       4       10      0       0       0       539     4       0       0       1       0       0       41      8       0       0       2       0       5       0       1       \n",
      "0       0       1       1       0       0       0       675     43      0       0       0       7       2       0       2       1       0       0       2       0       1       \n",
      "0       1       4       0       3       2       0       32      1612    1       1       35      10      7       0       8       3       0       4       0       0       2       \n",
      "0       0       0       0       0       0       0       0       2       15      0       0       0       0       0       0       0       0       0       0       0       0       \n",
      "1       0       16      0       0       4       0       0       0       0       1264    2       0       21      0       0       1       0       0       0       0       0       \n",
      "1       0       71      0       0       2       0       0       4       0       6       327     0       50      0       0       1       0       0       0       0       3       \n",
      "0       0       0       1       0       0       0       8       5       0       0       0       128     0       0       0       0       0       0       0       0       0       \n",
      "3       1       65      0       0       5       5       1       2       0       15      43      0       430     0       0       1       0       0       1       0       0       \n",
      "0       8       0       3       0       2       0       0       1       0       0       0       0       1       317     0       1       10      0       10      0       0       \n",
      "0       16      0       0       2       1       0       12      6       0       2       0       0       1       5       92      5       2       11      7       1       1       \n",
      "0       0       0       0       0       0       0       2       2       0       0       3       0       8       0       11      200     0       0       1       2       0       \n",
      "0       0       0       2       0       0       0       0       0       1       0       0       0       0       1       0       0       27      0       9       0       0       \n",
      "0       0       0       0       1       0       0       0       4       0       0       0       0       0       0       1       0       0       124     2       10      2       \n",
      "0       8       0       0       1       0       0       7       1       0       0       1       0       1       2       1       1       5       3       640     7       146     \n",
      "0       0       0       0       0       0       0       1       0       1       0       0       0       0       0       1       0       0       1       6       36      2       \n",
      "0       0       0       2       0       0       0       0       0       0       0       0       0       0       0       0       0       0       4       84      7       360     \n",
      "test result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          38     0.8514    0.7475    0.7960       590\n",
      "          39     0.7708    0.7014    0.7345       278\n",
      "          40     0.7800    0.7772    0.7786      1086\n",
      "          42     0.9673    0.9642    0.9657       307\n",
      "          43     0.8806    0.8082    0.8429        73\n",
      "          44     0.9293    0.9353    0.9323       618\n",
      "          45     0.9456    0.8694    0.9059       620\n",
      "          46     0.9048    0.9184    0.9115       735\n",
      "          47     0.9527    0.9345    0.9435      1725\n",
      "          48     0.8333    0.8824    0.8571        17\n",
      "          49     0.9598    0.9656    0.9627      1309\n",
      "         127     0.7483    0.7032    0.7251       465\n",
      "         142     0.8767    0.9014    0.8889       142\n",
      "         146     0.5819    0.7517    0.6560       572\n",
      "         148     0.8855    0.8980    0.8917       353\n",
      "         264     0.7480    0.5610    0.6411       164\n",
      "         399     0.9259    0.8734    0.8989       229\n",
      "         400     0.5625    0.6750    0.6136        40\n",
      "         432     0.8267    0.8611    0.8435       144\n",
      "         433     0.8040    0.7767    0.7901       824\n",
      "         434     0.5625    0.7500    0.6429        48\n",
      "         435     0.6818    0.7877    0.7310       457\n",
      "\n",
      "   micro avg     0.8521    0.8521    0.8521     10796\n",
      "   macro avg     0.8172    0.8201    0.8161     10796\n",
      "weighted avg     0.8577    0.8521    0.8534     10796\n",
      "\n",
      "================================================================================\n",
      "GBDT\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "train time: 79.887s\n",
      "test time:  1.166s\n",
      "train accuracy:   0.905\n",
      "test accuracy:   0.874\n",
      "confusion matrix:\n",
      "476     3       49      0       0       1       17      0       1       0       13      12      0       16      2       0       0       0       0       0       0       0       \n",
      "6       213     7       0       0       11      0       1       0       0       0       0       0       0       8       4       1       1       0       22      0       4       \n",
      "28      0       970     0       0       1       3       0       0       0       15      11      0       56      0       0       0       0       0       0       0       2       \n",
      "0       5       0       295     0       0       0       2       0       0       0       0       0       0       0       2       0       2       0       1       0       0       \n",
      "0       0       0       0       53      0       0       1       11      0       0       0       0       0       0       1       4       0       2       1       0       0       \n",
      "7       9       7       0       0       570     0       4       2       0       0       4       1       0       3       4       4       0       0       1       1       1       \n",
      "4       13      6       0       0       0       547     3       1       0       1       0       0       34      3       2       0       1       0       5       0       0       \n",
      "0       0       2       0       0       1       0       661     50      0       0       0       9       0       0       10      1       0       0       1       0       0       \n",
      "0       0       5       0       0       1       0       20      1676    0       4       6       2       5       0       1       0       0       4       1       0       0       \n",
      "0       0       0       0       0       0       2       0       0       15      0       0       0       0       0       0       0       0       0       0       0       0       \n",
      "3       0       12      0       0       0       0       0       0       0       1279    3       0       12      0       0       0       0       0       0       0       0       \n",
      "1       0       68      0       0       1       0       1       10      0       10      345     0       26      0       0       2       0       0       1       0       0       \n",
      "0       1       0       0       0       1       0       5       11      0       0       0       124     0       0       0       0       0       0       0       0       0       \n",
      "2       1       88      0       0       3       6       0       3       0       15      47      0       402     0       0       3       0       0       2       0       0       \n",
      "1       1       0       0       0       5       0       1       1       0       0       0       0       1       317     0       1       8       0       17      0       0       \n",
      "0       27      0       0       0       0       0       3       4       0       2       0       0       1       0       101     2       0       10      11      2       1       \n",
      "0       0       0       0       0       0       0       0       6       0       1       3       0       4       0       17      197     0       0       1       0       0       \n",
      "0       0       0       2       0       0       0       0       1       0       0       0       0       0       1       0       0       23      0       13      0       0       \n",
      "0       0       0       0       2       1       0       0       1       0       0       0       0       0       0       0       0       0       128     1       10      1       \n",
      "0       13      2       1       0       0       0       8       7       0       0       0       1       1       0       1       0       7       2       703     6       72      \n",
      "0       0       0       0       0       0       0       1       0       1       0       0       0       0       0       1       0       0       1       9       32      3       \n",
      "0       0       3       1       0       0       0       0       2       0       0       2       1       7       0       1       0       0       2       129     5       304     \n",
      "test result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          38     0.9015    0.8068    0.8515       590\n",
      "          39     0.7448    0.7662    0.7553       278\n",
      "          40     0.7957    0.8932    0.8416      1086\n",
      "          42     0.9866    0.9609    0.9736       307\n",
      "          43     0.9636    0.7260    0.8281        73\n",
      "          44     0.9564    0.9223    0.9390       618\n",
      "          45     0.9513    0.8823    0.9155       620\n",
      "          46     0.9297    0.8993    0.9142       735\n",
      "          47     0.9379    0.9716    0.9544      1725\n",
      "          48     0.9375    0.8824    0.9091        17\n",
      "          49     0.9545    0.9771    0.9656      1309\n",
      "         127     0.7968    0.7419    0.7684       465\n",
      "         142     0.8986    0.8732    0.8857       142\n",
      "         146     0.7115    0.7028    0.7071       572\n",
      "         148     0.9491    0.8980    0.9229       353\n",
      "         264     0.6966    0.6159    0.6537       164\n",
      "         399     0.9163    0.8603    0.8874       229\n",
      "         400     0.5476    0.5750    0.5610        40\n",
      "         432     0.8591    0.8889    0.8737       144\n",
      "         433     0.7650    0.8532    0.8067       824\n",
      "         434     0.5714    0.6667    0.6154        48\n",
      "         435     0.7835    0.6652    0.7195       457\n",
      "\n",
      "   micro avg     0.8736    0.8736    0.8736     10796\n",
      "   macro avg     0.8434    0.8195    0.8295     10796\n",
      "weighted avg     0.8753    0.8736    0.8732     10796\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.222s\n",
      "test time:  0.100s\n",
      "train accuracy:   0.995\n",
      "test accuracy:   0.902\n",
      "confusion matrix:\n",
      "531     3       26      0       0       0       9       0       2       0       5       4       0       10      0       0       0       0       0       0       0       0       \n",
      "3       249     4       1       0       2       0       0       1       0       0       0       0       0       4       3       1       0       0       10      0       0       \n",
      "27      0       1009    0       0       0       3       0       0       0       3       15      0       29      0       0       0       0       0       0       0       0       \n",
      "0       2       0       300     0       2       0       0       1       0       0       0       0       0       0       0       0       1       0       1       0       0       \n",
      "0       1       0       0       58      0       0       1       10      0       0       0       0       0       0       1       1       0       0       1       0       0       \n",
      "5       5       5       1       0       590     0       1       1       1       1       4       0       1       0       1       0       0       0       2       0       0       \n",
      "10      1       5       0       0       0       569     3       1       0       0       0       1       23      2       0       0       2       0       3       0       0       \n",
      "0       0       1       0       0       0       0       679     40      0       0       0       7       0       0       6       0       0       0       2       0       0       \n",
      "1       0       2       0       1       2       0       30      1676    0       2       4       0       2       0       0       0       0       3       2       0       0       \n",
      "0       0       0       0       0       0       0       0       2       15      0       0       0       0       0       0       0       0       0       0       0       0       \n",
      "3       0       9       0       0       1       0       0       3       0       1277    4       0       12      0       0       0       0       0       0       0       0       \n",
      "5       0       58      0       0       4       0       0       8       0       6       348     0       35      0       0       0       0       0       0       0       1       \n",
      "0       0       0       0       0       0       0       7       11      0       0       0       122     0       0       1       1       0       0       0       0       0       \n",
      "2       0       48      0       0       0       10      0       3       0       10      52      0       444     0       0       2       0       0       1       0       0       \n",
      "1       3       0       1       0       1       0       0       2       0       0       0       0       0       329     0       1       7       0       8       0       0       \n",
      "0       4       0       0       1       0       0       1       4       0       2       0       0       1       1       131     3       0       10      5       1       0       \n",
      "1       1       0       0       0       0       0       1       6       0       1       2       0       3       0       13      201     0       0       0       0       0       \n",
      "0       1       0       2       0       0       0       0       1       0       0       0       0       0       5       0       0       23      0       8       0       0       \n",
      "0       0       0       0       0       2       0       0       2       0       0       0       0       0       0       6       0       0       125     1       7       1       \n",
      "0       6       0       0       0       2       2       4       4       0       0       0       0       0       1       1       0       1       2       696     8       97      \n",
      "0       0       0       0       0       0       0       0       0       1       0       0       0       0       0       4       3       0       4       10      24      2       \n",
      "0       1       0       0       0       0       0       2       0       0       0       0       1       0       0       0       0       0       2       103     4       344     \n",
      "test result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          38     0.9015    0.9000    0.9008       590\n",
      "          39     0.8989    0.8957    0.8973       278\n",
      "          40     0.8646    0.9291    0.8957      1086\n",
      "          42     0.9836    0.9772    0.9804       307\n",
      "          43     0.9667    0.7945    0.8722        73\n",
      "          44     0.9736    0.9547    0.9641       618\n",
      "          45     0.9595    0.9177    0.9382       620\n",
      "          46     0.9314    0.9238    0.9276       735\n",
      "          47     0.9426    0.9716    0.9569      1725\n",
      "          48     0.8824    0.8824    0.8824        17\n",
      "          49     0.9770    0.9756    0.9763      1309\n",
      "         127     0.8037    0.7484    0.7751       465\n",
      "         142     0.9313    0.8592    0.8938       142\n",
      "         146     0.7929    0.7762    0.7845       572\n",
      "         148     0.9620    0.9320    0.9468       353\n",
      "         264     0.7844    0.7988    0.7915       164\n",
      "         399     0.9437    0.8777    0.9095       229\n",
      "         400     0.6765    0.5750    0.6216        40\n",
      "         432     0.8562    0.8681    0.8621       144\n",
      "         433     0.8159    0.8447    0.8301       824\n",
      "         434     0.5455    0.5000    0.5217        48\n",
      "         435     0.7730    0.7527    0.7627       457\n",
      "\n",
      "   micro avg     0.9022    0.9022    0.9022     10796\n",
      "   macro avg     0.8712    0.8480    0.8587     10796\n",
      "weighted avg     0.9022    0.9022    0.9018     10796\n",
      "\n",
      "================================================================================\n",
      "XGBoost\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
      "       n_estimators=100, n_jobs=1, nthread=None,\n",
      "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
      "       subsample=1, verbosity=1)\n",
      "train time: 88.570s\n",
      "test time:  4.326s\n",
      "train accuracy:   0.871\n",
      "test accuracy:   0.858\n",
      "confusion matrix:\n",
      "437     5       79      0       0       0       21      0       2       0       15      10      0       19      2       0       0       0       0       0       0       0       \n",
      "9       204     8       0       0       8       0       1       2       0       0       0       0       0       8       3       1       0       0       33      0       1       \n",
      "24      0       976     1       0       0       7       0       0       0       19      9       0       47      0       0       0       0       0       0       0       3       \n",
      "0       5       0       295     1       0       0       1       0       0       0       0       0       0       0       2       0       1       0       2       0       0       \n",
      "0       0       0       0       50      0       0       2       13      0       0       0       0       0       0       2       2       0       2       2       0       0       \n",
      "5       13      17      0       0       554     1       4       3       0       0       4       0       6       2       3       3       0       0       2       0       1       \n",
      "2       9       7       0       0       0       541     5       1       0       1       0       0       40      6       2       0       2       0       4       0       0       \n",
      "0       0       1       0       0       2       0       653     57      1       0       0       9       1       0       9       1       0       0       1       0       0       \n",
      "0       0       4       0       0       1       2       12      1685    0       2       5       1       8       0       1       0       0       4       0       0       0       \n",
      "0       0       0       0       0       0       0       0       0       17      0       0       0       0       0       0       0       0       0       0       0       0       \n",
      "0       0       22      0       0       4       0       0       3       0       1266    4       0       10      0       0       0       0       0       0       0       0       \n",
      "0       0       75      0       0       1       1       1       10      0       8       349     0       18      0       0       0       0       0       2       0       0       \n",
      "0       1       0       0       0       0       0       8       11      0       0       0       121     0       0       1       0       0       0       0       0       0       \n",
      "3       0       122     0       0       2       4       1       2       0       20      62      0       355     0       0       0       0       0       1       0       0       \n",
      "1       3       0       1       0       2       0       1       2       0       0       0       0       1       315     0       1       9       0       17      0       0       \n",
      "0       31      0       0       0       0       0       3       5       0       2       0       0       1       1       92      0       0       10      17      2       0       \n",
      "0       0       0       0       0       0       0       0       4       0       0       5       0       7       0       18      194     0       0       1       0       0       \n",
      "0       1       0       2       0       0       0       0       0       0       0       0       0       0       1       0       0       24      0       12      0       0       \n",
      "0       0       0       0       2       0       0       0       1       0       0       0       0       0       0       1       0       0       125     5       9       1       \n",
      "0       13      2       1       0       1       0       10      8       0       0       1       2       3       0       0       0       3       2       695     6       77      \n",
      "0       0       0       0       0       0       0       1       0       1       0       0       0       0       0       1       0       0       0       13      29      3       \n",
      "0       0       0       0       0       0       0       3       2       0       0       2       1       4       0       1       0       0       2       156     5       281     \n",
      "test result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          38     0.9085    0.7407    0.8161       590\n",
      "          39     0.7158    0.7338    0.7247       278\n",
      "          40     0.7433    0.8987    0.8137      1086\n",
      "          42     0.9833    0.9609    0.9720       307\n",
      "          43     0.9434    0.6849    0.7937        73\n",
      "          44     0.9635    0.8964    0.9288       618\n",
      "          45     0.9376    0.8726    0.9039       620\n",
      "          46     0.9249    0.8884    0.9063       735\n",
      "          47     0.9304    0.9768    0.9531      1725\n",
      "          48     0.8947    1.0000    0.9444        17\n",
      "          49     0.9497    0.9672    0.9584      1309\n",
      "         127     0.7738    0.7505    0.7620       465\n",
      "         142     0.9030    0.8521    0.8768       142\n",
      "         146     0.6827    0.6206    0.6502       572\n",
      "         148     0.9403    0.8924    0.9157       353\n",
      "         264     0.6765    0.5610    0.6133       164\n",
      "         399     0.9604    0.8472    0.9002       229\n",
      "         400     0.6154    0.6000    0.6076        40\n",
      "         432     0.8621    0.8681    0.8651       144\n",
      "         433     0.7217    0.8434    0.7778       824\n",
      "         434     0.5686    0.6042    0.5859        48\n",
      "         435     0.7657    0.6149    0.6820       457\n",
      "\n",
      "   micro avg     0.8575    0.8575    0.8575     10796\n",
      "   macro avg     0.8348    0.8034    0.8160     10796\n",
      "weighted avg     0.8610    0.8575    0.8567     10796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names,results = test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x468 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        plt.text(rect.get_x()+rect.get_width()/2.- 0.2, 1.03*height, '%.3f' % float(height))\n",
    "plt.figure(figsize=(20, 6.5))\n",
    "autolabel(plt.bar(range(len(results)), results, color='b', tick_label=names))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tunning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tunned_parameters = [{'n_estimators':[5,10,50,100],'n_jobs':[-1],'max_depth':[None, 10,50,100],\n",
    "                     \"max_features\":['auto','log2'],'min_samples_split' : [2,4,10] }]\n",
    "rf_cv = GridSearchCV(RandomForestClassifier(), tunned_parameters, cv=3,n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.2 s, sys: 334 ms, total: 4.53 s\n",
      "Wall time: 51.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid=[{'n_estimators': [5, 10, 50, 100], 'n_jobs': [-1], 'max_depth': [None, 10, 50, 100], 'max_features': ['auto', 'log2'], 'min_samples_split': [2, 4, 10]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_cv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9092100039698293\n",
      "{'max_depth': None, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1}\n"
     ]
    }
   ],
   "source": [
    "print(rf_cv.best_score_)\n",
    "print(rf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "train time: 0.651s\n",
      "test time:  0.319s\n",
      "train accuracy:   0.999\n",
      "test accuracy:   0.911\n",
      "confusion matrix:\n",
      "525     3       30      0       0       0       12      0       2       0       6       5       0       7       0       0       0       0       0       0       0       0       \n",
      "2       250     1       0       0       2       0       1       2       0       0       0       0       0       2       2       1       0       0       15      0       0       \n",
      "19      0       1030    0       0       0       1       0       0       0       3       10      0       23      0       0       0       0       0       0       0       0       \n",
      "0       1       0       300     0       0       0       1       0       0       0       0       0       0       0       1       0       1       0       3       0       0       \n",
      "0       0       0       0       59      0       0       1       7       0       0       0       0       0       0       2       2       0       1       1       0       0       \n",
      "5       4       0       1       0       598     0       1       2       0       0       4       0       0       0       1       0       0       0       2       0       0       \n",
      "6       1       3       0       0       0       574     3       1       0       0       0       0       24      2       0       1       2       0       3       0       0       \n",
      "0       0       0       0       0       0       0       677     46      0       0       0       6       0       0       6       0       0       0       0       0       0       \n",
      "1       0       0       0       0       2       0       19      1683    0       5       6       0       3       0       0       0       0       4       2       0       0       \n",
      "0       0       0       0       0       0       0       0       2       15      0       0       0       0       0       0       0       0       0       0       0       0       \n",
      "3       0       6       0       0       2       0       0       6       0       1280    5       0       7       0       0       0       0       0       0       0       0       \n",
      "2       0       49      0       0       2       0       0       9       0       5       362     0       36      0       0       0       0       0       0       0       0       \n",
      "0       2       0       0       0       0       0       4       12      0       0       0       124     0       0       0       0       0       0       0       0       0       \n",
      "3       0       32      0       0       0       8       0       4       0       13      45      0       465     0       0       1       0       0       1       0       0       \n",
      "1       1       0       1       0       1       0       0       1       0       0       0       0       1       325     0       1       9       0       12      0       0       \n",
      "0       5       0       0       1       0       0       2       3       0       2       0       0       1       0       132     2       0       10      5       1       0       \n",
      "0       1       0       0       0       0       0       0       7       0       1       3       0       2       0       11      203     0       0       0       1       0       \n",
      "0       1       0       2       0       0       0       0       0       0       0       0       0       0       5       0       0       25      0       7       0       0       \n",
      "0       0       0       0       2       0       0       0       2       0       0       0       0       0       0       2       0       0       126     1       11      0       \n",
      "0       7       1       1       0       0       0       2       3       0       0       0       0       0       1       1       0       2       2       704     6       94      \n",
      "0       0       0       0       1       0       0       2       0       1       0       0       0       0       0       1       0       0       3       7       32      1       \n",
      "0       0       0       1       0       0       0       0       0       0       0       0       1       0       0       0       0       0       2       104     5       344     \n",
      "test result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          38     0.9259    0.8898    0.9075       590\n",
      "          39     0.9058    0.8993    0.9025       278\n",
      "          40     0.8941    0.9484    0.9205      1086\n",
      "          42     0.9804    0.9772    0.9788       307\n",
      "          43     0.9365    0.8082    0.8676        73\n",
      "          44     0.9852    0.9676    0.9763       618\n",
      "          45     0.9647    0.9258    0.9449       620\n",
      "          46     0.9495    0.9211    0.9351       735\n",
      "          47     0.9392    0.9757    0.9571      1725\n",
      "          48     0.9375    0.8824    0.9091        17\n",
      "          49     0.9734    0.9778    0.9756      1309\n",
      "         127     0.8227    0.7785    0.8000       465\n",
      "         142     0.9466    0.8732    0.9084       142\n",
      "         146     0.8172    0.8129    0.8151       572\n",
      "         148     0.9701    0.9207    0.9448       353\n",
      "         264     0.8302    0.8049    0.8173       164\n",
      "         399     0.9621    0.8865    0.9227       229\n",
      "         400     0.6410    0.6250    0.6329        40\n",
      "         432     0.8514    0.8750    0.8630       144\n",
      "         433     0.8120    0.8544    0.8326       824\n",
      "         434     0.5714    0.6667    0.6154        48\n",
      "         435     0.7836    0.7527    0.7679       457\n",
      "\n",
      "   micro avg     0.9108    0.9108    0.9108     10796\n",
      "   macro avg     0.8818    0.8647    0.8725     10796\n",
      "weighted avg     0.9114    0.9108    0.9107     10796\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9108002964060763"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf = RandomForestClassifier(**rf_cv.best_params_)\n",
    "benchmark(best_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_importance(clf):\n",
    "    with open(\"feature_name\",\"r\",encoding='utf-8') as f:\n",
    "        feature_name = f.read().strip()\n",
    "    feature_name = feature_name.split()\n",
    "    feature_importance = clf.feature_importances_\n",
    "    feature_name_with_import = zip(feature_name,feature_importance)\n",
    "    feature_name_with_import = sorted(feature_name_with_import,key=lambda x : x[1],reverse=True) \n",
    "    for name,score in feature_name_with_import:\n",
    "        print(\"{:<35} : {:<5f}\".format(name,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LetterInMaterial                    : 0.124408\n",
      "FirstLetterBeforeUnderline          : 0.098918\n",
      "ChineseInProblem                    : 0.076728\n",
      "LetterInAnalysis                    : 0.072222\n",
      "LetterInProblem                     : 0.070201\n",
      "LetterInAnswer                      : 0.067242\n",
      "ChineseInAnalysis                   : 0.060642\n",
      "UnderlineNumInMaterial              : 0.042083\n",
      "PeopleInMaterial                    : 0.041734\n",
      "ChineseInMaterial                   : 0.040883\n",
      "UnderlineEmptyNumInMaterial         : 0.039573\n",
      "NumOfBlankAfterUnderline            : 0.033249\n",
      "SingleChoiceAns                     : 0.032523\n",
      "ChangeSentenceInProblem             : 0.027748\n",
      "MultiChoiceAns                      : 0.023711\n",
      "HasUnderlineInProblemOrMaterial     : 0.023504\n",
      "HasSoundmark                        : 0.017990\n",
      "HasProperFormInMaterial             : 0.013837\n",
      "HasBracketInProblem                 : 0.013678\n",
      "HasLetterBeforeBlank                : 0.012149\n",
      "HasBlankInProblem                   : 0.009395\n",
      "HasBoldInProblemOrMaterial          : 0.009118\n",
      "ChangeWordInProblemOrMaterial       : 0.008879\n",
      "HasCorrectStyleWord                 : 0.007114\n",
      "PeopleInAnalysis                    : 0.005895\n",
      "HasImgInProblemOrMaterial           : 0.004618\n",
      "BlankNumInMaterial                  : 0.003771\n",
      "HasListeningWord                    : 0.003456\n",
      "HasAudio                            : 0.003068\n",
      "HasChineseWord                      : 0.002900\n",
      "HasItalicInProblemOrMaterial        : 0.002594\n",
      "SameWordInProblemAndAnswer          : 0.002373\n",
      "TranslateWordInProblemOrAnalyze     : 0.002024\n",
      "HasImgWordInProblemOrMaterial       : 0.000645\n",
      "HasMatchSymbol                      : 0.000507\n",
      "CorrectionWordInProblemOrMaterial   : 0.000310\n",
      "HasConversationWord                 : 0.000180\n",
      "KeyWordWriteInProblem               : 0.000130\n",
      "AllOptionHasImg                     : 0.000000\n",
      "CorrectionInAns                     : 0.000000\n",
      "HasBoldInOption                     : 0.000000\n",
      "HasNoMaterial                       : 0.000000\n",
      "HasUnderlineInOption                : 0.000000\n",
      "OptionNum                           : 0.000000\n"
     ]
    }
   ],
   "source": [
    "feature_importance(best_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
